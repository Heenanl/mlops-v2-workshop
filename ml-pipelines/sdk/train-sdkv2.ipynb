{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this workshop, you need:\n",
    "\n",
    "* An Azure Machine Learning workspace. \n",
    "* The Azure Machine Learning Python SDK v2 installed. \n",
    "\n",
    "To install the SDK you can either,\n",
    "\n",
    "Create a compute instance, which already has installed the latest AzureML Python SDK and is pre-configured for ML workflows.\n",
    "\n",
    "Use the followings commands to install Azure ML Python SDK v2:\n",
    "\n",
    "```bash\n",
    "conda activate <virtual_env_name>\n",
    "pip install azure-ai-ml==1.27+\n",
    "```\n",
    "\n",
    "If you're using a virtual env, make sure to install the sdk inside the virtual env.\n",
    "\n",
    "The virtual environment for sdkv2 on Azure Notebooks is called `azureml_py310_sdkv2`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "source": [
    "## Connect to ML Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to a workspace, you need to provide a subscription, resource group and workspace name. These details are used in the `MLClient` from `azure.ai.ml` to get a handle to the required Azure Machine Learning workspace.\n",
    "\n",
    "In the following example, the default Azure authentication is used along with the default workspace configuration or from any `config.json` file you might have copied into the folders structure. If no `config.json` is found, then you need to manually introduce the subscription_id, resource_group and workspace when creating `MLClient`.\n",
    "\n",
    "```python\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your AzureML workspace\n",
    "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "    resource_group = \"<RESOURCE_GROUP>\"\n",
    "    workspace = \"<AZUREML_WORKSPACE_NAME>\"\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml import MLClient, command, Input, Output, load_component\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import Data, Environment\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "from azure.ai.ml.dsl import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter details of your AML workspace\n",
    "subscription_id = \"5bef918d-59f1-49d6-897b-919e5d5c05a0\"\n",
    "resource_group = \"rg-gasunimlopsv2-prod\"\n",
    "workspace = \"mlw-gasunimlopsv2-prod\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1670200031039
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## (Option) 1. Create Managed Compute\n",
    "\n",
    "A compute is a designated compute resource where you run your job or host your endpoint. Azure Machine learning supports the following types of compute:\n",
    "\n",
    "- **Compute instance** - a fully configured and managed development environment in the cloud. You can use the instance as a training or inference compute for development and testing. It's similar to a virtual machine on the cloud.\n",
    "\n",
    "- **Compute cluster** - a managed-compute infrastructure that allows you to easily create a cluster of CPU or GPU compute nodes in the cloud.\n",
    "\n",
    "- **Inference cluster** - used to deploy trained machine learning models to Azure Kubernetes Service. You can create an Azure Kubernetes Service (AKS) cluster from your Azure ML workspace, or attach an existing AKS cluster.\n",
    "\n",
    "- **Attached compute** - You can attach your own compute resources to your workspace and use them for training and inference.\n",
    "\n",
    "You can create a compute using the Studio, the cli and the sdk.\n",
    "\n",
    "<hr>\n",
    "\n",
    "We can create a **compute instance** with cli v2 or sdk v2 using the following syntax:\n",
    "\n",
    "<center>\n",
    "<img src=\"../../imgs/create_compute_instance.png\" width = \"700px\" alt=\"Create Compute Instance cli vs sdk\">\n",
    "</center>\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "We can create a **compute cluster** with cli v2 or sdk v2 using the following syntax:\n",
    "\n",
    "<center>\n",
    "<img src=\"../../imgs/create_compute_cluster.png\" width = \"700px\" alt=\"Create Compute Instance cli vs sdk\">\n",
    "</center>\n",
    "\n",
    "\n",
    "Let's create a managed compute cluster for the training workload."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "my_cluster = AmlCompute(\n",
    "    name=\"cpu-cluster-CA\",\n",
    "    type=\"amlcompute\", \n",
    "    size=\"STANDARD_DS3_V2\", \n",
    "    min_instances=0, \n",
    "    max_instances=4,\n",
    "    location=\"westeurope\", \t\n",
    ")\n",
    "\n",
    "ml_client.compute.begin_create_or_update(my_cluster)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute not found; Proceding to create\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute,IdentityConfiguration,ManagedIdentityConfiguration\n",
    "from azure.ai.ml.constants import ManagedServiceIdentityType\n",
    "\n",
    "# Create an identity configuration for a system-assigned managed identity\n",
    "identity_config = IdentityConfiguration(type = ManagedServiceIdentityType.USER_ASSIGNED)\n",
    "\n",
    "# Create an identity configuration from the user-assigned managed identity\n",
    "managed_identity = ManagedIdentityConfiguration(resource_id=\"/subscriptions/5bef918d-59f1-49d6-897b-919e5d5c05a0/resourceGroups/rg-gasunimlopsv2-prod/providers/Microsoft.ManagedIdentity/userAssignedIdentities/gasunie-mi-prod\")\n",
    "identity_config = IdentityConfiguration(type = ManagedServiceIdentityType.USER_ASSIGNED, user_assigned_identities=[managed_identity])\n",
    "\n",
    "\n",
    "try:\n",
    "    ml_client.compute.get(name=\"cpu-test-mi\")\n",
    "    print(\"Compute already exists\")\n",
    "\n",
    "except:\n",
    "    print(\"Compute not found; Proceding to create\")\n",
    "    \n",
    "    my_cluster = AmlCompute(\n",
    "    name=\"cpu-cluster-mi\",\n",
    "    type=\"amlcompute\", \n",
    "    size=\"STANDARD_DS3_V2\", \n",
    "    min_instances=0, \n",
    "    max_instances=4,\n",
    "    identity=identity_config\n",
    "    )\n",
    "    ml_client.compute.begin_create_or_update(my_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 2. Register Data Asset\n",
    "\n",
    "**Datastore** - Azure Machine Learning Datastores securely keep the connection information to your data storage on Azure, so you don't have to code it in your scripts.\n",
    "\n",
    "An Azure Machine Learning datastore is a **reference** to an **existing** storage account on Azure. The benefits of creating and using a datastore are:\n",
    "* A common and easy-to-use API to interact with different storage type. \n",
    "* Easier to discover useful datastores when working as a team.\n",
    "* When using credential-based access (service principal/SAS/key), the connection information is secured so you don't have to code it in your scripts.\n",
    "\n",
    "Supported Data Resources: \n",
    "\n",
    "* Azure Storage blob container\n",
    "* Azure Storage file share\n",
    "* Azure Data Lake Gen 1\n",
    "* Azure Data Lake Gen 2\n",
    "* Azure SQL Database \n",
    "* Azure PostgreSQL Database\n",
    "* Azure MySQL Database\n",
    "\n",
    "It is not a requirement to use Azure Machine Learning datastores - you can use storage URIs directly assuming you have access to the underlying data.\n",
    "\n",
    "You can create a datastore using the Studio, the cli and the sdk.\n",
    "\n",
    "<hr>\n",
    "\n",
    "We can create a **datastore** with cli v2 or sdk v2 using the following syntax:\n",
    "\n",
    "<center>\n",
    "<img src=\"../../imgs/create_datastore.png\" width = \"700px\" alt=\"Create Datastore cli vs sdk\">\n",
    "</center>\n",
    "\n",
    "\n",
    "\n",
    "**Data asset** - Create data assets in your workspace to share with team members, version, and track data lineage.\n",
    "\n",
    "By creating a data asset, you create a reference to the data source location, along with a copy of its metadata. \n",
    "\n",
    "The benefits of creating data assets are:\n",
    "\n",
    "* You can **share and reuse data** with other members of the team such that they do not need to remember file locations.\n",
    "* You can **seamlessly access data** during model training (on any supported compute type) without worrying about connection strings or data paths.\n",
    "* You can **version** the data.\n",
    "\n",
    "<hr>\n",
    "\n",
    "We can create a **data asset** with cli v2 or sdk v2 using the following syntax:\n",
    "\n",
    "<center>\n",
    "<img src=\"../../imgs/create_data_asset.png\" width = \"700px\" alt=\"Create Data Asset cli vs sdk\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1670200033270
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading taxi-data.csv\u001b[32m (< 1 MB): 100%|##########| 1.22M/1.22M [00:00<00:00, 4.55MB/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data({'path': 'azureml://subscriptions/5bef918d-59f1-49d6-897b-919e5d5c05a0/resourcegroups/rg-gasunimlopsv2-prod/workspaces/mlw-gasunimlopsv2-prod/datastores/workspaceblobstore/paths/LocalUpload/2e56e9007690a9db90f90b8830ddcde4/taxi-data.csv', 'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'taxi-data', 'description': 'Taxi dataset', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/5bef918d-59f1-49d6-897b-919e5d5c05a0/resourceGroups/rg-gasunimlopsv2-prod/providers/Microsoft.MachineLearningServices/workspaces/mlw-gasunimlopsv2-prod/data/taxi-data/versions/1', 'Resource__source_path': '', 'base_path': 'c:\\\\Users\\\\heenarefai\\\\Documents\\\\code\\\\mlops-v2-workshop\\\\ml-pipelines\\\\sdk', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x0000016DAF058590>, 'serialize': <msrest.serialization.Serializer object at 0x0000016DAF546430>, 'version': '1', 'latest_version': None, 'datastore': None})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data = Data(\n",
    "    path=\"../../data/taxi-data.csv\",\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description=\"Taxi dataset\",\n",
    "    name=\"taxi-data\"\n",
    ")\n",
    "ml_client.data.create_or_update(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Register Train Environment\n",
    "\n",
    "Azure Machine Learning environments define the execution environments for your **jobs** or **deployments** and encapsulate the dependencies for your code. \n",
    "\n",
    "Azure ML uses the environment specification to create the Docker container that your **training** or **scoring code** runs in on the specified compute target.\n",
    "\n",
    "Create an environment from a\n",
    "* conda specification\n",
    "* Docker image\n",
    "* Docker build context\n",
    "\n",
    "There are two types of environments in Azure ML: **curated** and **custom environments**. Curated environments are predefined environments containing popular ML frameworks and tooling. Custom environments are user-defined.\n",
    "\n",
    "<hr>\n",
    "\n",
    "We can register an **environment** with cli v2 or sdk v2 using the following syntax:\n",
    "\n",
    "<center>\n",
    "<img src=\"../../imgs/create_environment.png\" width = \"700px\" alt=\"Create Environment cli vs sdk\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1670200035753
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Environment({'arm_type': 'environment_version', 'latest_version': None, 'image': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04', 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'taxi-train-env', 'description': 'Environment created from a Docker image plus Conda environment to train taxi model.', 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': False, 'id': '/subscriptions/5bef918d-59f1-49d6-897b-919e5d5c05a0/resourceGroups/rg-gasunimlopsv2-prod/providers/Microsoft.MachineLearningServices/workspaces/mlw-gasunimlopsv2-prod/environments/taxi-train-env/versions/1', 'Resource__source_path': '', 'base_path': 'c:\\\\Users\\\\heenarefai\\\\Documents\\\\code\\\\mlops-v2-workshop\\\\ml-pipelines\\\\sdk', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x0000016DAF066FD0>, 'serialize': <msrest.serialization.Serializer object at 0x0000016DAF547D90>, 'version': '1', 'conda_file': {'channels': ['defaults', 'anaconda', 'conda-forge'], 'dependencies': ['python=3.7.5', 'pip', {'pip': ['azureml-mlflow==1.38.0', 'azure-ai-ml==1.0.0', 'pyarrow==10.0.0', 'ruamel.yaml==0.17.21', 'scikit-learn==0.24.1', 'pandas==1.2.1', 'joblib==1.0.0', 'matplotlib==3.3.3']}]}, 'build': None, 'inference_config': None, 'os_type': 'Linux', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': '{\\n  \"channels\": [\\n    \"defaults\",\\n    \"anaconda\",\\n    \"conda-forge\"\\n  ],\\n  \"dependencies\": [\\n    \"python=3.7.5\",\\n    \"pip\",\\n    {\\n      \"pip\": [\\n        \"azureml-mlflow==1.38.0\",\\n        \"azure-ai-ml==1.0.0\",\\n        \"pyarrow==10.0.0\",\\n        \"ruamel.yaml==0.17.21\",\\n        \"scikit-learn==0.24.1\",\\n        \"pandas==1.2.1\",\\n        \"joblib==1.0.0\",\\n        \"matplotlib==3.3.3\"\\n      ]\\n    }\\n  ]\\n}'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_environment = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
    "    conda_file=\"../../environment/train-conda.yml\",\n",
    "    name=\"taxi-train-env\",\n",
    "    description=\"Environment created from a Docker image plus Conda environment to train taxi model.\",\n",
    ")\n",
    "\n",
    "ml_client.environments.create_or_update(my_environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Create Pipeline Job\n",
    "\n",
    "**AML Job**:\n",
    "\n",
    "Azure ML provides several ways to train your models, from code-first solutions to low-code solutions:\n",
    "\n",
    "* Azure ML supports script files in python, R, Java, Julia or C#. All you need to learn is YAML format and command lines to use Azure ML.\n",
    "\n",
    "* Distributed Training: AML supports integrations with popular frameworks, PyTorch and TensorFlow. Both frameworks employ data parallelism & model parallelism for distributed training.\n",
    "\n",
    "* Automated ML - Train models without extensive data science or programming knowledge.\n",
    "\n",
    "* Designer - drag and drop web-based UI.\n",
    "\n",
    "<hr>\n",
    "\n",
    "We can submit a **job** with cli v2 or sdk v2 using the following syntax:\n",
    "\n",
    "<center>\n",
    "<img src=\"../../imgs/create_job.png\" width = \"700px\" alt=\"Create Job cli vs sdk\">\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "    \n",
    "**AML Pipelines**:\n",
    "\n",
    "An AML pipeline is an independently executable workflow of a complete machine learning task. It helps standardizing the best practices of producing a machine learning model: The core of a machine learning pipeline is to split a complete machine learning task into a multistep workflow. Each step is a manageable component that can be developed, optimized, configured, and automated individually. \n",
    "\n",
    "<hr>\n",
    "\n",
    "We can submit a **pipeline job** with cli v2 or sdk v2 using the following syntax:\n",
    "\n",
    "<center>\n",
    "<img src=\"../../imgs/create_pipeline.png\" width = \"700px\" alt=\"Create Pipeline cli vs sdk\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1670200036044
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create pipeline job\n",
    "parent_dir = \"../../components\"\n",
    "\n",
    "# 1. Load components\n",
    "prepare_data = load_component(source=parent_dir + \"/prep.yml\")\n",
    "train_model = load_component(source=parent_dir + \"/train.yml\")\n",
    "evaluate_model = load_component(source=parent_dir + \"/evaluate.yml\")\n",
    "register_model = load_component(source=parent_dir + \"/register.yml\")\n",
    "\n",
    "# 2. Construct pipeline\n",
    "@pipeline()\n",
    "def taxi_training_pipeline(raw_data, enable_monitoring, table_name):\n",
    "    \n",
    "    prepare = prepare_data(\n",
    "        raw_data=raw_data,\n",
    "        enable_monitoring=enable_monitoring, \n",
    "        table_name=table_name\n",
    "    )\n",
    "\n",
    "    train = train_model(\n",
    "        train_data=prepare.outputs.train_data\n",
    "    )\n",
    "\n",
    "    evaluate = evaluate_model(\n",
    "        model_name=\"taxi-model\",\n",
    "        model_input=train.outputs.model_output,\n",
    "        test_data=prepare.outputs.test_data\n",
    "    )\n",
    "\n",
    "\n",
    "    register = register_model(\n",
    "        model_name=\"taxi-model\",\n",
    "        model_path=train.outputs.model_output,\n",
    "        evaluation_output=evaluate.outputs.evaluation_output\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"pipeline_job_train_data\": prepare.outputs.train_data,\n",
    "        \"pipeline_job_test_data\": prepare.outputs.test_data,\n",
    "        \"pipeline_job_trained_model\": train.outputs.model_output,\n",
    "        \"pipeline_job_score_report\": evaluate.outputs.evaluation_output,\n",
    "    }\n",
    "\n",
    "\n",
    "pipeline_job = taxi_training_pipeline(\n",
    "    Input(type=AssetTypes.URI_FILE, path=\"taxi-data@latest\"), \"false\", \"taximonitoring\"\n",
    ")\n",
    "\n",
    "# set pipeline level compute\n",
    "pipeline_job.settings.default_compute = \"cpu-cluster\"\n",
    "# set pipeline level datastore\n",
    "pipeline_job.settings.default_datastore = \"workspaceblobstore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1670200062228
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "\u001b[32mUploading prep (0.0 MBs): 100%|##########| 4244/4244 [00:00<00:00, 93218.96it/s]\n",
      "\u001b[39m\n",
      "\n",
      "\u001b[32mUploading train (0.01 MBs): 100%|##########| 5578/5578 [00:00<00:00, 122361.84it/s]\n",
      "\u001b[39m\n",
      "\n",
      "\u001b[32mUploading evaluate (0.01 MBs): 100%|##########| 6471/6471 [00:00<00:00, 28266.84it/s]\n",
      "\u001b[39m\n",
      "\n",
      "\u001b[32mUploading register (0.0 MBs): 100%|##########| 4741/4741 [00:00<00:00, 20160.88it/s]\n",
      "\u001b[39m\n",
      "\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>pipeline_samples</td><td>nifty_cord_dy7st64wdv</td><td>pipeline</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/nifty_cord_dy7st64wdv?wsid=/subscriptions/5bef918d-59f1-49d6-897b-919e5d5c05a0/resourcegroups/rg-gasunimlopsv2-prod/workspaces/mlw-gasunimlopsv2-prod&amp;tid=1a640b76-52c0-4a5c-b26b-3148406b593f\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineJob({'inputs': {'raw_data': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x0000016DB0733850>, 'enable_monitoring': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x0000016DB04A3D40>, 'table_name': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x0000016DB04A3980>}, 'outputs': {'pipeline_job_train_data': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x0000016DB0731550>, 'pipeline_job_test_data': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x0000016DB0733A50>, 'pipeline_job_trained_model': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x0000016DB04A1310>, 'pipeline_job_score_report': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x0000016DB04A16D0>}, 'jobs': {}, 'component': PipelineComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'auto_delete_setting': None, 'name': 'azureml_anonymous', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\heenarefai\\\\Documents\\\\code\\\\mlops-v2-workshop\\\\ml-pipelines\\\\sdk', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000016DB05438C0>, 'version': '1', 'schema': None, 'type': 'pipeline', 'display_name': 'taxi_training_pipeline', 'is_deterministic': None, 'inputs': {'raw_data': {}, 'enable_monitoring': {}, 'table_name': {}}, 'outputs': {'pipeline_job_train_data': {}, 'pipeline_job_test_data': {}, 'pipeline_job_trained_model': {}, 'pipeline_job_score_report': {}}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {'prepare': Command({'parameters': {}, 'init': False, 'name': 'prepare', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': '', 'base_path': 'c:\\\\Users\\\\heenarefai\\\\Documents\\\\code\\\\mlops-v2-workshop\\\\ml-pipelines\\\\sdk', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000016DB0078A60>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'raw_data': '${{parent.inputs.raw_data}}', 'enable_monitoring': '${{parent.inputs.enable_monitoring}}', 'table_name': '${{parent.inputs.table_name}}'}, 'job_outputs': {'train_data': '${{parent.outputs.pipeline_job_train_data}}', 'test_data': '${{parent.outputs.pipeline_job_test_data}}'}, 'inputs': {'raw_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000016DAF4A2C50>, 'enable_monitoring': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000016DAF4A2780>, 'table_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000016DAF4A2A40>}, 'outputs': {'train_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x0000016DA84FF650>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x0000016DAF495E50>}, 'component': 'azureml_anonymous:3c55c9e2-450f-4029-931d-40d7a3d2cac3', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': 'b7dafbcb-9d9a-40a6-b146-7fd17de369fb', 'source': 'YAML.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'parent_job_name': None, 'swept': False}), 'train': Command({'parameters': {}, 'init': False, 'name': 'train', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': '', 'base_path': 'c:\\\\Users\\\\heenarefai\\\\Documents\\\\code\\\\mlops-v2-workshop\\\\ml-pipelines\\\\sdk', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000016DAF545B70>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'train_data': '${{parent.jobs.prepare.outputs.train_data}}'}, 'job_outputs': {'model_output': '${{parent.outputs.pipeline_job_trained_model}}'}, 'inputs': {'train_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000016DAF4A2990>}, 'outputs': {'model_output': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x0000016DAF497950>}, 'component': 'azureml_anonymous:652c7ffa-25cd-4987-bf2a-18a572cfde35', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': 'b826e482-3f09-47ec-899f-8a267f5f9740', 'source': 'YAML.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'parent_job_name': None, 'swept': False}), 'evaluate': Command({'parameters': {}, 'init': False, 'name': 'evaluate', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': '', 'base_path': 'c:\\\\Users\\\\heenarefai\\\\Documents\\\\code\\\\mlops-v2-workshop\\\\ml-pipelines\\\\sdk', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000016DAF0AC130>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'model_name': 'taxi-model', 'model_input': '${{parent.jobs.train.outputs.model_output}}', 'test_data': '${{parent.jobs.prepare.outputs.test_data}}'}, 'job_outputs': {'evaluation_output': '${{parent.outputs.pipeline_job_score_report}}'}, 'inputs': {'model_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000016DAF4A3070>, 'model_input': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000016DAF4A2830>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000016DAF4A2E60>}, 'outputs': {'evaluation_output': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x0000016DB03B7350>}, 'component': 'azureml_anonymous:3fa0cf7c-0847-4f67-8690-dc9f59990353', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': 'c1f0d044-6653-4533-9410-946424476c55', 'source': 'YAML.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'parent_job_name': None, 'swept': False}), 'register': Command({'parameters': {}, 'init': False, 'name': 'register', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': '', 'base_path': 'c:\\\\Users\\\\heenarefai\\\\Documents\\\\code\\\\mlops-v2-workshop\\\\ml-pipelines\\\\sdk', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000016DB0519EF0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'model_name': 'taxi-model', 'model_path': '${{parent.jobs.train.outputs.model_output}}', 'evaluation_output': '${{parent.jobs.evaluate.outputs.evaluation_output}}'}, 'job_outputs': {}, 'inputs': {'model_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000016DAF4A2D00>, 'model_path': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000016DAF4A26D0>, 'evaluation_output': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000016DAF4A22B0>}, 'outputs': {}, 'component': 'azureml_anonymous:70c742e9-cef5-4b28-943c-f2d30f42b814', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '02d06112-65df-4cc3-9015-75c80e3209e6', 'source': 'YAML.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'parent_job_name': None, 'swept': False})}, 'job_types': {'command': 4}, 'job_sources': {'YAML.COMPONENT': 4}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'NotStarted', 'log_files': None, 'name': 'nifty_cord_dy7st64wdv', 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/Azure/mlops-v2-workshop.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': '059e65589f428d873fc4b0ea2ad68a942cf276c0', 'azureml.git.dirty': 'True'}, 'print_as_yaml': False, 'id': '/subscriptions/5bef918d-59f1-49d6-897b-919e5d5c05a0/resourceGroups/rg-gasunimlopsv2-prod/providers/Microsoft.MachineLearningServices/workspaces/mlw-gasunimlopsv2-prod/jobs/nifty_cord_dy7st64wdv', 'Resource__source_path': '', 'base_path': 'c:\\\\Users\\\\heenarefai\\\\Documents\\\\code\\\\mlops-v2-workshop\\\\ml-pipelines\\\\sdk', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x0000016DB04A0E60>, 'serialize': <msrest.serialization.Serializer object at 0x0000016DB0474C20>, 'display_name': 'taxi_training_pipeline', 'experiment_name': 'pipeline_samples', 'compute': None, 'services': {'Tracking': {'endpoint': 'azureml://westeurope.api.azureml.ms/mlflow/v1.0/subscriptions/5bef918d-59f1-49d6-897b-919e5d5c05a0/resourceGroups/rg-gasunimlopsv2-prod/providers/Microsoft.MachineLearningServices/workspaces/mlw-gasunimlopsv2-prod?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/nifty_cord_dy7st64wdv?wsid=/subscriptions/5bef918d-59f1-49d6-897b-919e5d5c05a0/resourcegroups/rg-gasunimlopsv2-prod/workspaces/mlw-gasunimlopsv2-prod&tid=1a640b76-52c0-4a5c-b26b-3148406b593f', 'type': 'Studio'}}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_job, experiment_name=\"pipeline_samples\"\n",
    ")\n",
    "pipeline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
